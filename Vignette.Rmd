---
title: "Vignette: How to simulate and fit data with stratified-by-species sampling
  for validation"
author: "Jacob Oram"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview 

This document accompanies the manuscript "Investigation into stratified-by-species validation of species labels for acoustic surveys", so that the reader may conduct similar simulations on their own. The manuscript provides a complete example analysis; here, we focus on the mechanics of setting up and running the necessary code to recreate the simulation study and explore alternative validation designs for different species assemblages. 

__[A brief paragraph or two describing the necessary terms and key workflow attributes for this vignette to make sense.]__

## Conducting your own simulation study

### Step 1: Installing and loading required packages

After cloning this repo, the next step is loading the necessary packages in R. To simulate, fit and visualize models used with a stratified-by-species validation design using our code, the following packages are necessary: 

- `tidyverse`
- `nimble`
- `coda`
- `rstan`
- `parallel`
- `here`

If you do not have one or more of these packages installed, run the following, with the name of the missing package in place of `your_package_name_here`: 

```{r eval=FALSE, echo=TRUE}
install.packages("your_package_name_here")
```

After installing the necessary packages, load these libraries by calling

```{r eval=FALSE, echo=TRUE}
library(tidyverse)
library(nimble)
library(coda)
library(rstan)
library(parallel)
library(here)
```


### Step 2: Set up your working directory

In the course of the simulation study, several objects are saved: 

- simulated datasets (optional)
- simulated datasets after validation (optional)
- model fits (optional)
- individual summaries for one dataset/validation scenario combination (optional)
- overall summaries for each validation scenario (always saved)

Functions that save any part of the simulation require a `directory` argument be specified. If you choose to save model fits or individual summaries, our simulation functions expect your working directory to contain the folders 

- `PathToYourWorkingDirectory/ThetaID/fits` 
- `PathToYourWorkingDirectory/ThetaID/individual_summaries` 

Above,  `PathToYourWorkingDirectory` is replaced with the file path to your working directory (e.g. `~/Documents` for the local Documents folder on Mac) and `ID` is replaced with the classifier scenario ID. Visually, this file structure should appear as  follows: 

```{=latex}
\begin{itemize}
 \item YourWorkingDirectory
 \begin{itemize}
    \item ThetaID
    \begin{itemize}
      \item fits
      \item individual\_summaries
    \end{itemize}
 \end{itemize}
\end{itemize}
```

See the Testing folder in this repo for an example (ignore the blank placeHold.txt files, which are simply there to retain the empty directory structure). Here, we use numbers for the classifier scenarios. The first scenario has `ID=1`, giving the paths to the necessary directories  `your/working/directory/Testing/Theta1/fits` and `your/working/directory/Testing/Theta1/individual_summaries`. 

### Step 3: Simulate data 

With the required folder structure set up, we can now simulate data using stratified-by-species validation. This is accomplished using the `simulate_BySpeciesValidation` function. Load this function by running

```{r}
source("Data Simulation/simulate_BySpeciesValidation.R")
```

Next, determine the species assemblage to simulate, and the number of sites and visits. We start by assigning the occurrence and relative activity parameters for the three species, then define the number of sites and visits.

```{r}
psi <- c(0.3, 0.6, 0.9)
lambda <- c(11, 2, 4)

# Define sites and visits 
nspecies <- length(psi)
nsites <- 100
nvisits <- 4
```

The data simulation function also requires that we define the classifier and validation scenarios to be used in the simulations. To define a classifier, you can manually enter a matrix:

```{r}
test_theta1 <- matrix(c(0.9, 0.05, 0.05,
                       0.1, 0.85, 0.05, 
                       0.02, 0.03, 0.95), byrow = TRUE, nrow = 3)

test_theta1
```
This can also be accomplished by using the `rdirch` function from NIMBLE:

```{r}
test_theta2 <- t(apply(18*diag(nspecies) + 2, 1, function(x) nimble::rdirch(alpha = x)))
test_theta2
```
However you choose to generate the $\Theta$ matrix, make sure that the rows sum to 1: 

```{r}
rowSums(test_theta1)
rowSums(test_theta2)
```

The next input that needs to be defined for the simulation is the validation efforts for each species label. These are to be stored in a dataframe with each row corresponding to a validation design you would like to investigate. In a simple scenario with the three species above and two levels of effort for each, we could generate an appropriate dataframe by running `expand.grid`. This yields 8 distinct validation scenarios:  

```{r}
val_scenarios <- expand.grid(spp1 = c(.75, .5), spp2 = c(.25, .5), spp3 = c(.25, .75))
val_scenarios
nrow(val_scenarios)
```

With the appropriate inputs defined, we can simulate data. Note that in this example we opt to save both the simulated datasets with all true species labels retained (`save_datasets = TRUE`), as well as the simulated datasets with all true species labels masked except for those that were validated according to the validation scenario (`save_masked_datasets = TRUE`). These datasets are saved in the Testing folder of the current working directory. Note that if you specify the directory using `here::here()`, as we have, the subfolder must have a slash in front of it (e.g., `"/Testing"`). Note that every dataset under every validation set is saved separately, meaning that there will be  $2 \times$ `n_datasets` + `n_datasets` $\times$ `nrow(scenarios_dataframe)` objects saved in your directory! 

```{r message=FALSE}
fake_data <- simulate_BySpeciesValidation(
  n_datasets = 5, 
  scenarios_dataframe = val_scenarios, 
  nsites = nsites, 
  nvisits = nvisits, 
  nspecies = nspecies,
  psi = psi, 
  lambda = lambda,
  theta = test_theta2, 
  save_datasets = TRUE,
  save_masked_datasets = TRUE,
  directory = paste0(here::here(), "/Testing")
)
```

To see what is available, we can investigate `fake_data`. The output is a list, containing three objects: 

- `full_datasets`: A list of length `n_datasets` with unmasked datasets (i.e., full validation of all recordings).
If `save_datasets = TRUE`, then these will be saved individually in `directory` as dataset_n.rds, where n 
is the dataset number.
- `zeros`: A list of length `n_datasets` containing all of the site-visits where no recordings of a certain classification were observed. For example, if, in dataset 10, there were no calls from species 1 that were classified as  3 on visit 4 to site 156, then the 10th entry of this list would contain a dataset with a row corresponding to site = 156, visit = 4, true_spp = 1, id_spp = 3, with count = 0. These zeros are necessary for housekeeping in the model-fitting process. If `save_datasets = TRUE`, the zeros for each dataset will be saved in `directory` individually as site_visits_without_calls_in_dataset_n.rds, where n is the dataset number.
- `masked_dfs`: A nested list containing each dataset masked under each scenario. `masked_dfs[[9]][[27]]` contains dataset 27, assuming validation scenario 9. If `save_masked_datasets = TRUE`, then each dataset/scenario combination is saved individually in `directory` as 
dataset_n_masked_under_scenario_s.rds, where n is the dataset number and s is the scenario number. 

Examples of each are given below: 

```{r}
full_dfs <- fake_data$full_datasets
head(full_dfs[[1]])
```

```{r}
site_visits_without_calls <- fake_data$zeros
head(site_visits_without_calls[[1]])
```

```{r}
masked_dfs <- fake_data$masked_dfs

# View dataset 3 with scenario 7 validation effort.
head(masked_dfs[[7]][[3]])
```

### Step 4: Fit the data 

### Step 5: Visualize simulations 

## Using saved datasets and model fits 

